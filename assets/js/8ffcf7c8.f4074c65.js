"use strict";(self.webpackChunkeliza_docs=self.webpackChunkeliza_docs||[]).push([[61064],{84918:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"Discord/development/agent-dev-school/chat_2024-11-28","title":"agent-dev-school 2024-11-28","description":"Summary","source":"@site/community/Discord/development/agent-dev-school/chat_2024-11-28.md","sourceDirName":"Discord/development/agent-dev-school","slug":"/Discord/development/agent-dev-school/chat_2024-11-28","permalink":"/eliza/community/Discord/development/agent-dev-school/chat_2024-11-28","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"3d-ai-tv 2024-12-09","permalink":"/eliza/community/Discord/collaborations/3d-ai-tv/chat_2024-12-09"},"next":{"title":"agent-dev-school 2024-11-29","permalink":"/eliza/community/Discord/development/agent-dev-school/chat_2024-11-29"}}');var o=n(74848),s=n(28453);const a={},d="agent-dev-school 2024-11-28",c={},l=[{value:"Summary",id:"summary",level:2},{value:"FAQ",id:"faq",level:2},{value:"Who Helped Who",id:"who-helped-who",level:2},{value:"Action Items",id:"action-items",level:2},{value:"Technical Tasks",id:"technical-tasks",level:3},{value:"Documentation Needs",id:"documentation-needs",level:3}];function r(e){const t={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"agent-dev-school-2024-11-28",children:"agent-dev-school 2024-11-28"})}),"\n",(0,o.jsx)(t.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(t.p,{children:"The main technical discussion revolved around creating a solution to periodically extract coders' questions from the chat, synthesize 'next class topic', manage Extract-Transform-Load (ETL) processes using GitHub & Discord data. The proposed approach involves setting up cron jobs and building repositories for easy accessibility of this information."}),"\n",(0,o.jsx)(t.h2,{id:"faq",children:"FAQ"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"What does it mean to pass the providers as in yesterday's video? Is data ingested automatically by the agent, and what endpoints are exposed after pnpm start for clients interacting directly with agents? (asked by @shaw (00:15))"}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"who-helped-who",children:"Who Helped Who"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"@yikesawjeez (13:57) helped @shaw with Building an ETL pipeline for Discord data extraction and management. by providing @Odilitime@jin will work together to build a solution based on yikesawjeez's suggestion."}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"action-items",children:"Action Items"}),"\n",(0,o.jsx)(t.h3,{id:"technical-tasks",children:"Technical Tasks"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Set up a cron job to periodically dump coders' questions, synthesize 'next class topic', and manage ETL from Discord. (mentioned by @yikesawjeez)"}),"\n"]}),"\n",(0,o.jsx)(t.h3,{id:"documentation-needs",children:"Documentation Needs"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Create a repository to extract data from both GitHub and Discord for easy accessibility, transformation, and utilization. (mentioned by @Odilitime)"}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(r,{...e})}):r(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>d});var i=n(96540);const o={},s=i.createContext(o);function a(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);