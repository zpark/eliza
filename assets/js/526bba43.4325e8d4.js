"use strict";(self.webpackChunk_elizaos_docs=self.webpackChunk_elizaos_docs||[]).push([[86682],{22442:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/autodocs-8a392130c5360412d86633a7fe86316c.svg"},28357:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/autodocs-b386bd7760266769995b1137322d16c4.jpg"},54268:e=>{e.exports=JSON.parse('{"permalink":"/blog/autodocs","editUrl":"https://github.com/elizaos/eliza/tree/develop/docs/blog/autodocs.mdx","source":"@site/blog/autodocs.mdx","title":"Automating Eliza\'s Documentation","description":"A look into the agentic automation workflows being used to maintain a high-quality, up-to-date knowledge base.","date":"2025-05-14T00:00:00.000Z","tags":[{"inline":false,"label":"Documentation","permalink":"/blog/tags/documentation","description":"Documentation and guides"},{"inline":false,"label":"CI/CD","permalink":"/blog/tags/ci-cd","description":"Continuous integration and deployment"},{"inline":false,"label":"Automation","permalink":"/blog/tags/automation","description":"Automation tools and workflows"},{"inline":false,"label":"DevOps","permalink":"/blog/tags/devops","description":"DevOps practices and tools"},{"inline":false,"label":"Open Source","permalink":"/blog/tags/open-source","description":"Open source contributions"},{"inline":false,"label":"AI","permalink":"/blog/tags/ai","description":"Artificial intelligence"},{"inline":false,"label":"Docs as Code","permalink":"/blog/tags/docs-as-code","description":"Documentation as code practices"}],"readingTime":12.18,"hasTruncateMarker":true,"authors":[{"name":"jin","title":"Contributor","url":"https://github.com/madjin","socials":{"twitter":"https://twitter.com/dankvr","github":"https://github.com/madjin"},"imageURL":"https://avatars.githubusercontent.com/u/32600939?v=4","key":"jin","page":null}],"frontMatter":{"slug":"autodocs","title":"Automating Eliza\'s Documentation","description":"A look into the agentic automation workflows being used to maintain a high-quality, up-to-date knowledge base.","authors":"jin","date":"2025-05-14T00:00:00.000Z","tags":["documentation","ci-cd","automation","devops","open-source","ai","docs-as-code"],"image":"/blog/autodocs.jpg"},"unlisted":false,"lastUpdatedBy":"Shaw","prevItem":{"title":"Easy macOS Development Setup for ElizaOS","permalink":"/blog/macos-dev-setup-guide"},"nextItem":{"title":"auto.fun: Where AI Projects Thrive, Not Just Launch","permalink":"/blog/autofun-intro"}}')},56684:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>c});var i=s(54268),t=s(31085),o=s(71184);const a={slug:"autodocs",title:"Automating Eliza's Documentation",description:"A look into the agentic automation workflows being used to maintain a high-quality, up-to-date knowledge base.",authors:"jin",date:new Date("2025-05-14T00:00:00.000Z"),tags:["documentation","ci-cd","automation","devops","open-source","ai","docs-as-code"],image:"/blog/autodocs.jpg"},r="Automating Eliza's Documentation",l={authorsImageUrls:[void 0]},c=[{value:"The Broader Information Ecosystem",id:"the-broader-information-ecosystem",level:2},{value:"Automating Content Generation &amp; Updates: The Mechanics",id:"automating-content-generation--updates-the-mechanics",level:2},{value:"News Aggregation &amp; Syndication",id:"news-aggregation--syndication",level:3},{value:"AI Context Files: <code>llms.txt</code> &amp; <code>llms-full.txt</code>",id:"ai-context-files-llmstxt--llms-fulltxt",level:3},{value:"JSDoc &amp; Typedoc",id:"jsdoc--typedoc",level:3},{value:"README Translations via AI",id:"readme-translations-via-ai",level:3},{value:"Supporting Scripts",id:"supporting-scripts",level:3},{value:"Dynamic Package Showcase (eliza.how/packages)",id:"dynamic-package-showcase-elizahowpackages",level:3},{value:"Automation Backbone: GitHub Actions",id:"automation-backbone-github-actions",level:2},{value:"Living Documentation: Challenges, Learnings &amp; Future Vision",id:"living-documentation-challenges-learnings--future-vision",level:2},{value:"Current Challenges &amp; Learnings",id:"current-challenges--learnings",level:3},{value:"Future Vision &amp; Enhancements",id:"future-vision--enhancements",level:3}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:['Our previous post, "',(0,t.jsx)(n.a,{href:"/blog/taming-info",children:"Tools for Taming Information"}),",\" highlighted the need for effective knowledge management in a dynamic project like Eliza. This follow-up explores the 'how': our CI/CD practices for automating documentation."]}),"\n",(0,t.jsx)(n.p,{children:"By treating docs as code, we boost consistency, accuracy, update speed, and reduce manual work for contributors, building a more robust and accessible knowledge base for everyone."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(28357).A+"",width:"1536",height:"1024"})}),"\n","\n",(0,t.jsx)(n.h2,{id:"the-broader-information-ecosystem",children:"The Broader Information Ecosystem"}),"\n",(0,t.jsxs)(n.p,{children:["Eliza thrive on information from diverse sources (GitHub, Discord, etc.). Efficiently capturing and processing this data is vital. The diagram below shows our information ecosystem, where data streams are collected, AI-enriched, and centralized in our ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/knowledge",children:"knowledge repository"}),'. This post focuses on the "\ud83d\udcda docs/" portion and its automation.']}),"\n",(0,t.jsxs)(n.p,{children:["The following diagram illustrates this broader flow, showing how various data streams are collected, processed, enriched (often with AI), and centralized into our ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/knowledge",children:"knowledge repository"}),". This repository then feeds various consumption layers, including AI agents, human users, and visual dashboards."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(22442).A+"",width:"1414",height:"1533"})}),"\n",(0,t.jsx)("summary",{children:"View mermaid"}),"\n",(0,t.jsx)(i,{children:(0,t.jsx)(n.mermaid,{value:'flowchart\n    %% Data collection systems side by side\n\nsubgraph DataCollection["Data Collection Systems"]\nsubgraph ELIZA["elizaos.github.io (Contributor Analytics)"]\nEG_INGEST["\ud83d\udce5 Ingest GitHub Data\nPRs, Issues, Comments"] --\x3e EG_DB[("\ud83d\udcbe Pglite DB +\nDiffable Format")]\nEG_PROCESS["\u2699\ufe0f Process & Score\nContributions"]\nEG_DB <--\x3e EG_PROCESS\nEG_PROCESS --\x3e EG_EXPORT["\ud83d\udcca Export\nJSON Files"]\nEG_PROCESS <--\x3e EG_SUMMARIZE["\ud83d\udcdd Generate\nAI Summaries"]\nEG_SUMMARIZE --\x3e EG_DEPLOY["\ud83d\ude80 Deploy to\nGitHub Pages"]\nEG_EXPORT --\x3e EG_DEPLOY\nend\n\n    subgraph AI_News["ai-news (Data Collector/Miner)"]\n        direction LR\n        AI_EXTRACT["\u26cf\ufe0f Extract Raw Data\n\nDiscord, X, Github\nBlockchain, Telegram"]\nAI_STORE[("\ud83d\udcbe Encrypted\nPglite DB")]\nAI_ENRICH["\ud83e\udde0 AI Analysis\n& Enrichment"]\nAI_GENERATE["\ud83d\udcdd Generate\nAI Summaries"]\nAI_DEPLOY["\ud83d\ude80 Deploy to\nGitHub Pages"]\nend\n\n        %% Define connections explicitly\n        AI_EXTRACT --\x3e AI_STORE <--\x3e AI_ENRICH --\x3e AI_GENERATE --\x3e AI_DEPLOY\n        AI_GENERATE --\x3e AI_STORE\n\n    subgraph DailySilk["daily-silk (AI Twitter)"]\n        direction LR\n        TL["Twitter lists about AI"]\n        LLM["LLM summarization"]\n        TL --\x3e LLM --\x3e DS_FETCH["\u26cf\ufe0f Discord Fetch\n\nEmbedded Messages"] --\x3e DS_JSON[("\ud83d\udcbe JSON Files\nYYYY-MM-DD")] --\x3e DS_DEPLOY["\ud83d\ude80 Deploy to\nGitHub Pages"]\n\n    end\n\n\n    end\n\n\n    %% Knowledge Repository with properly contained sources\n    subgraph KNOW["knowledge (Central Repository)"]\n\n        subgraph KR_SOURCES["Data Sources"]\n            DOCS["\ud83d\udcda docs/\n\nElizaOS Documentation\n\n- Packages & Partners"]\n  GITHUB["\ud83d\udc19 github/\n  Stats, PRs, Issues, Commits"]\n  AINEWS["\ud83d\udcf0 ai-news/\n  ElizaOS & Hyperfy\n  Summaries"]\n  DS["\ud83d\udcf0 daily-silk/\n  AI twitter news"]\n\n              DOCS---GITHUB---AINEWS---DS\n          end\n\n          KR_MAP["\ud83d\uddfa\ufe0f Context Map\n\n  Structured JSON"]\n\n          subgraph KR_OUTPUTS["Outputs"]\n              KR_STRATEGIC["\ud83e\udde9 Strategic Context\n\n  AI Council Insights"]\n  KR_NOTES["\ud83d\udcd2 HackMD Notes\n  Prompt-Generated\n  Content"]\n  end\n\n          subgraph KR_PROMPTS["Prompt Templates"]\n              COMMS["\ud83d\udcac comms/\n\n  Communication"] --- DEV["\ud83d\udcbb dev/\n  Development"] --- STRATEGY["\ud83c\udfaf strategy/\n  Strategic Planning"]\n  end\n\n          %% Internal connections within KNOW\n          KR_SOURCES --\x3e|"\u23f0 Generate Context\n\n  Daily 5:00 UTC"| KR_MAP\n  KR_MAP --\x3e KR_OUTPUTS\n  KR_PROMPTS --\x3e|"Generate\n  Content"| KR_NOTES\n  end\n\n      %% Consumption layer\n      subgraph ConsumptionLayer["Consumption Layer"]\n          RAG["\ud83e\udd16 RAG Systems\n\n  AI Agents"] <-.-> USER["\ud83d\udc64 Human\n  Users"] <-.-> SHOW["\ud83c\udfac AI Shows\n  Visualizations"]\n  end\n\n      %% Connections between systems - simplified\n      AI_DEPLOY -.->|"\u23f0 Sync Daily 4:00 UTC"| KNOW\n      EG_DEPLOY -.->|"\u23f0 Sync Daily 4:00 UTC"| KNOW\n      DS_DEPLOY -.->|"\u23f0 Sync Daily 4:00 UTC"| KNOW\n\n      %% Main flow connection to consumption\n      KR_OUTPUTS & KR_NOTES --\x3e ConsumptionLayer\n\n      %% Styling\n      classDef process fill:#f7e8ff,stroke:#9966cc,stroke-width:1px,color:#333,font-weight:bold,border-radius:8px\n      classDef storage fill:#ffe6e6,stroke:#ff6666,stroke-width:1px,color:#333,font-weight:bold,border-radius:16px\n      classDef output fill:#e6ffe6,stroke:#66cc66,stroke-width:1px,color:#333,font-weight:bold,border-radius:8px\n      classDef source fill:#fff9e6,stroke:#ffcc66,stroke-width:1px,color:#333,font-weight:bold,border-radius:8px\n\n      class AI_EXTRACT,AI_ENRICH,AI_GENERATE,EG_INGEST,EG_EXPORT,EG_SUMMARIZE process\n      class AI_STORE,EG_DB,DS_JSON storage\n      class AI_DEPLOY,EG_DEPLOY,DS_DEPLOY,KR_MAP,KR_STRATEGIC,KR_NOTES output\n      class DOCS,GITHUB,DS,AINEWS,SILK,ARCHIVE,COMMS,DEV,STRATEGY source\n\n      %% Style subgraphs\n      style AI_News fill:#f9f0ff,stroke:#9966cc,stroke-width:2px,color:#6600cc,font-weight:bold\n      style ELIZA fill:#fff0e6,stroke:#ff9933,stroke-width:2px,color:#cc6600,font-weight:bold\n      style KNOW fill:#e6fff0,stroke:#33cc99,stroke-width:2px,color:#006633,font-weight:bold\n      style KR_SOURCES fill:#fff9e6,stroke:#ffcc66,stroke-width:2px,color:#997a00,font-weight:bold\n      style KR_PROMPTS fill:#e6f7ff,stroke:#66ccff,stroke-width:2px,color:#006699,font-weight:bold\n      style KR_OUTPUTS fill:#ffe6f7,stroke:#ff66cc,stroke-width:2px,color:#990066,font-weight:bold\n      style ConsumptionLayer fill:#e6ffff,stroke:#66cccc,stroke-width:2px,color:#006666,font-weight:bold\n'})}),"\n",(0,t.jsx)(n.p,{children:'While this diagram captures the full scope, this article will zoom in on the "\ud83d\udcda docs/" portion within the "KNOW (Central Repository)" and how our CI/CD pipelines automate its maintenance and enrichment.'}),"\n",(0,t.jsxs)(n.p,{children:["Our documentation itself lives within the ",(0,t.jsx)(n.code,{children:"packages/docs"})," directory and is built using ",(0,t.jsx)(n.a,{href:"https://docusaurus.io/",children:"Docusaurus"}),", a static site generator optimized for creating clean, accessible documentation sites. Key configuration files like ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/docusaurus.config.ts",children:(0,t.jsx)(n.code,{children:"docusaurus.config.ts"})})," define the site's structure, plugins, themes, and navigation, including sidebars managed via ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/sidebars.ts",children:(0,t.jsx)(n.code,{children:"sidebars.ts"})}),"."]}),"\n",(0,t.jsx)(n.p,{children:"We manage several key types of content:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Core Documentation"}),": Conceptual explanations, guides, and tutorials for ElizaOS."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"API Reference"}),": Automatically generated from our TypeScript code comments."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"REST API Docs"}),": Derived from OpenAPI specifications."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Packages"}),": Documentation for individual adapters, clients, and plugins."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Partners & Community"}),": Information related to our ecosystem partners and community initiatives."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Blog & News"}),": Regular updates, articles, and aggregated news from the AI and ElizaOS space."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Static assets, such as images, diagrams, and important text files like ",(0,t.jsx)(n.a,{href:"https://eliza.how/llms.txt",children:(0,t.jsx)(n.code,{children:"llms.txt"})})," (a context file for AI models, found in ",(0,t.jsx)(n.code,{children:"packages/docs/static/"}),"), are also managed within this structure."]}),"\n",(0,t.jsx)(n.p,{children:"With this context in mind, let's delve into how automation helps us keep this diverse set of documentation current and accurate."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"automating-content-generation--updates-the-mechanics",children:"Automating Content Generation & Updates: The Mechanics"}),"\n",(0,t.jsx)(n.p,{children:"Maintaining accurate and timely documentation requires robust automation. Here's a concise look at the key mechanisms we employ:"}),"\n",(0,t.jsx)(n.h3,{id:"news-aggregation--syndication",children:"News Aggregation & Syndication"}),"\n",(0,t.jsxs)(n.p,{children:["Freshness in our ",(0,t.jsx)(n.a,{href:"https://eliza.how/news",children:"news section"})," is critical. The ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/scripts/update-news.sh",children:(0,t.jsx)(n.code,{children:"update-news.sh"})})," script, orchestrated by the ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/update-news.yml",children:(0,t.jsx)(n.code,{children:"update-news.yml"})})," GitHub workflow, automates this."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Process"}),": It fetches new Markdown articles daily from a predefined source (currently ",(0,t.jsx)(n.a,{href:"https://m3-org.github.io/ai-news/elizaos/md",children:"AI News for elizaOS"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Integration"}),": New news files are added to ",(0,t.jsx)(n.code,{children:"packages/docs/news/"})," and the ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/scripts/repomix.config.json",children:(0,t.jsx)(n.code,{children:"repomix.config.json"})})," is updated. This ensures our AI context files (see below) also benefit from the latest news, enhancing the knowledge of our AI assistants."]}),"\n"]}),"\n",(0,t.jsxs)(n.h3,{id:"ai-context-files-llmstxt--llms-fulltxt",children:["AI Context Files: ",(0,t.jsx)(n.a,{href:"https://eliza.how/llms.txt",children:(0,t.jsx)(n.code,{children:"llms.txt"})})," & ",(0,t.jsx)(n.a,{href:"https://eliza.how/llms-full.txt",children:(0,t.jsx)(n.code,{children:"llms-full.txt"})})]}),"\n",(0,t.jsxs)(n.p,{children:["These files are crucial for providing our AI systems (like documentation Q&A bots or RAG agents) with relevant, up-to-date context about ElizaOS. We use ",(0,t.jsx)(n.a,{href:"https://github.com/yamadashy/repomix",children:"Repomix"}),", a powerful tool that packs your entire repository into a single, AI-friendly file, perfect for when you need to feed your codebase to Large Language Models (LLMs)."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Generation"}),": The ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/llmstxt-generator.yml",children:(0,t.jsx)(n.code,{children:"llmstxt-generator.yml"})})," workflow uses ",(0,t.jsx)(n.code,{children:"repomix"}),", configured by ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/scripts/repomix.config.json",children:(0,t.jsx)(n.code,{children:"repomix.config.json"})})," and ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/scripts/repomix-full.config.json",children:(0,t.jsx)(n.code,{children:"repomix-full.config.json"})}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Content"}),": ",(0,t.jsx)(n.code,{children:"repomix"})," scans specified project files and documentation, compiling them into ",(0,t.jsx)(n.code,{children:"packages/docs/static/llms.txt"})," (a general overview) and ",(0,t.jsx)(n.code,{children:"packages/docs/static/llms-full.txt"})," (a more comprehensive technical deep-dive)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Impact"}),": This ensures our AI can answer questions based on the latest code and documentation without manual re-training on every minor change."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"jsdoc--typedoc",children:"JSDoc & Typedoc"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/jsdoc-automation.yml",children:(0,t.jsx)(n.code,{children:"jsdoc-automation.yml"})})," workflow leverages our ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/autodoc/README.md",children:(0,t.jsx)(n.code,{children:"autodoc"})})," package to help maintain JSDoc comments in our TypeScript codebase. These comments are then processed by the ",(0,t.jsx)(n.a,{href:"https://typedoc-plugin-markdown.org/plugins/docusaurus",children:"Docusaurus Typedoc Plugin"})," (configured in ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/docusaurus.config.ts",children:(0,t.jsx)(n.code,{children:"docusaurus.config.ts"})}),") to generate the browsable API reference in ",(0,t.jsx)(n.a,{href:"https://eliza.how/api",children:(0,t.jsx)(n.code,{children:"/api"})}),". This plugin integrates TypeDoc into the Docusaurus lifecycle, presetting relevant ",(0,t.jsx)(n.code,{children:"typedoc-plugin-markdown"})," options and generating a configurable Docusaurus sidebar."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"OpenAPI for REST:"})," Our REST API documentation in ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/tree/develop/packages/docs/docs/rest",children:(0,t.jsx)(n.code,{children:"/docs/rest"})})," is generated from an OpenAPI specification file (",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/src/openapi/eliza-v1.yaml",children:(0,t.jsx)(n.code,{children:"packages/docs/src/openapi/eliza-v1.yaml"})}),") using ",(0,t.jsx)(n.code,{children:"docusaurus-plugin-openapi-docs"}),". This ensures the API docs are always in sync with the defined contract."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"readme-translations-via-ai",children:"README Translations via AI"}),"\n",(0,t.jsxs)(n.p,{children:["To broaden accessibility, the ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/generate-readme-translations.yml",children:(0,t.jsx)(n.code,{children:"generate-readme-translations.yml"})})," workflow uses an AI model to translate our main project ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/README.md",children:"README.md"})," into multiple languages. These translations are then committed to the repository."]}),"\n",(0,t.jsx)(n.h3,{id:"supporting-scripts",children:"Supporting Scripts"}),"\n",(0,t.jsxs)(n.p,{children:["Several other scripts in ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/scripts/README.md",children:(0,t.jsx)(n.code,{children:"packages/docs/scripts/"})})," handle more specialized tasks:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/scripts/update-partner-pages.js",children:(0,t.jsx)(n.code,{children:"update-partner-pages.js"})}),": This script automates the creation and maintenance of individual documentation pages for our partners, located under ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/tree/develop/packages/docs/partners/",children:(0,t.jsx)(n.code,{children:"packages/docs/partners/"})}),". It reads partner data (name, description, logo, website, social links, etc.) from ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/src/data/partners.tsx",children:(0,t.jsx)(n.code,{children:"packages/docs/src/data/partners.tsx"})}),". For each partner, it generates a standardized Markdown page, ensuring consistency and ease of updates by modifying a central data source."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/scripts/summarize.sh",children:(0,t.jsx)(n.code,{children:"summarize.sh"})}),": A versatile command-line utility that leverages AI models via the OpenRouter API to summarize various file types, including text, JSON, and even MP3 audio (which it first transcribes using ",(0,t.jsx)(n.a,{href:"https://github.com/Vaibhavs10/insanely-fast-whisper",children:(0,t.jsx)(n.code,{children:"insanely-fast-whisper"})}),"). This script can be used to quickly generate summaries of content. For instance, when new videos are uploaded (e.g., to YouTube), ",(0,t.jsx)(n.code,{children:"summarize.sh"})," can be used to transcribe and summarize the content, forming the basis for new documentation pages. It offers options for custom prompts, model selection, and output file specification."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/scripts/get-changelog.py",children:(0,t.jsx)(n.code,{children:"get-changelog.py"})}),": Helps in generating changelogs from repository history."]}),"\n"]}),"\n",(0,t.jsxs)(n.h3,{id:"dynamic-package-showcase-elizahowpackages",children:["Dynamic Package Showcase (",(0,t.jsx)(n.a,{href:"https://eliza.how/packages",children:"eliza.how/packages"}),")"]}),"\n",(0,t.jsx)(n.p,{children:"Our package showcase is a key resource for discovering ElizaOS adapters, clients, and plugins. Its content is dynamically generated through an automated process:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Registry Fetching"}),": The ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/scripts/update-registry.js",children:(0,t.jsx)(n.code,{children:"update-registry.js"})})," script periodically fetches the list of available packages from the central ",(0,t.jsx)(n.a,{href:"https://raw.githubusercontent.com/elizaos-plugins/registry/refs/heads/main/index.json",children:"ElizaOS Plugins Registry"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Custom Data Merging"}),": This script enriches the registry data with custom descriptions and preview image paths defined in ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/src/data/plugin-descriptions.json",children:(0,t.jsx)(n.code,{children:"plugin-descriptions.json"})}),". This file allows us to provide more curated information than what might be available directly from GitHub repository descriptions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data Generation"}),": The processed data is then used to generate ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/src/data/registry-users.tsx",children:(0,t.jsx)(n.code,{children:"registry-users.tsx"})}),", which exports a structured array of all packages."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Display Logic"}),": ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/src/data/users.tsx",children:(0,t.jsx)(n.code,{children:"users.tsx"})})," consumes this array, defines tags, and handles sorting for the showcase."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Rendering"}),": Finally, the React components in ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/tree/develop/packages/docs/src/pages/showcase/",children:(0,t.jsx)(n.code,{children:"packages/docs/src/pages/showcase/"})})," (primarily ",(0,t.jsx)(n.code,{children:"index.tsx"})," and its sub-components) render the interactive showcase."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI-Assisted Summaries"}),": The ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/packages/docs/scripts/plugin_summary_prompt.txt",children:(0,t.jsx)(n.code,{children:"plugin_summary_prompt.txt"})})," can be used with ",(0,t.jsx)(n.code,{children:"summarize.sh"})," to help generate or update descriptions within ",(0,t.jsx)(n.code,{children:"plugin-descriptions.json"}),", further streamlining content maintenance for the showcase."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This automated pipeline ensures the package showcase remains comprehensive and up-to-date with minimal manual intervention."}),"\n",(0,t.jsx)(n.p,{children:'These automated processes form the core of our "docs-as-code" philosophy, reducing toil and improving the quality and timeliness of our documentation.'}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"automation-backbone-github-actions",children:"Automation Backbone: GitHub Actions"}),"\n",(0,t.jsxs)(n.p,{children:["All this automation is powered by our CI/CD pipelines, defined using ",(0,t.jsx)(n.a,{href:"https://github.com/features/actions",children:"GitHub Actions"}),". These workflows, located in our ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/README.md",children:(0,t.jsx)(n.code,{children:".github/workflows/"})})," directory, are the engine that keeps our documentation building, testing, and deploying smoothly."]}),"\n",(0,t.jsx)(n.p,{children:"Key workflows ensure documentation integrity and timely updates:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.strong,{children:["Core CI Checks (",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/ci.yaml",children:(0,t.jsx)(n.code,{children:"ci.yaml"})}),", ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/pr.yaml",children:(0,t.jsx)(n.code,{children:"pr.yaml"})}),"):"]})," On every push or pull request, these workflows run essential checks. For documentation, this includes linting Markdown files, checking for broken links, and ensuring the Docusaurus site builds successfully. This catches errors early, before they reach the live documentation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Automated Content Generation Triggers:"})," As detailed in the previous section, workflows like ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/update-news.yml",children:(0,t.jsx)(n.code,{children:"update-news.yml"})}),", ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/llmstxt-generator.yml",children:(0,t.jsx)(n.code,{children:"llmstxt-generator.yml"})}),", ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/jsdoc-automation.yml",children:(0,t.jsx)(n.code,{children:"jsdoc-automation.yml"})}),", and ",(0,t.jsx)(n.a,{href:"https://github.com/elizaOS/eliza/blob/develop/.github/workflows/generate-readme-translations.yml",children:(0,t.jsx)(n.code,{children:"generate-readme-translations.yml"})})," are triggered on schedules or specific events (e.g., pushes to main branches) to automatically update relevant documentation sections or supporting files."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Deployment:"})," The Docusaurus site is automatically deployed upon merges to the main branch using the command ",(0,t.jsx)(n.code,{children:"USE_SSH=true bun run deploy"}),". This ensures that approved changes are reflected on the live documentation site (",(0,t.jsx)(n.a,{href:"https://eliza.how/docs",children:"eliza.how/docs"}),") promptly."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This CI/CD setup not only automates repetitive tasks but also enforces quality standards, ensuring that our documentation remains a reliable resource."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"living-documentation-challenges-learnings--future-vision",children:"Living Documentation: Challenges, Learnings & Future Vision"}),"\n",(0,t.jsx)(n.p,{children:"Treating documentation as code and automating its lifecycle is a journey, not a destination. While our current setup significantly improves efficiency and consistency, we continuously learn and identify areas for enhancement."}),"\n",(0,t.jsx)(n.h3,{id:"current-challenges--learnings",children:"Current Challenges & Learnings"}),"\n",(0,t.jsx)(n.p,{children:"Our docs-as-code pipeline is robust, but we're always working to make it better. This means focusing on:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Speed:"})," Making sure docs build quickly"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Quality:"})," Double-checking any content written by AI to ensure it's accurate and clear"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Teamwork for Tools:"})," Keeping all the different software parts and scripts working together smoothly, especially as we add new things"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"future-vision--enhancements",children:"Future Vision & Enhancements"}),"\n",(0,t.jsx)(n.p,{children:"Our goal is to make the documentation process even more seamless, intelligent, and contributor-friendly. We're exploring enhancements like:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Smarter Triggers:"})," Targeting CI jobs to run only when relevant files change."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Smarter Link Checks:"})," Moving beyond basic broken link detection to validating link relevance."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Enhanced AI Assistance:"})," Using AI to identify outdated docs or suggest improvements based on search queries."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Automated Video Documentation:"})," Using ",(0,t.jsx)(n.code,{children:"summarize.sh"})," to transcribe, summarize, and draft PRs for new video content, plus automating ",(0,t.jsx)(n.code,{children:"VideoGallery"})," updates."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Automated Plugin Descriptions:"})," Using CI and ",(0,t.jsx)(n.code,{children:"summarize.sh"})," to propose updates to ",(0,t.jsx)(n.code,{children:"plugin-descriptions.json"})," when new plugins or README changes are detected."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Faster Feedback Loops:"})," Optimizing workflows for quicker contributor feedback on PRs."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI-Driven Content Strategy:"})," Using site analytics to guide AI in suggesting or outlining new documentation."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"We're always refining these processes. Your contributions and feedback via GitHub or Discord are invaluable in helping us build an even better documentation experience, we're listening!"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},71184:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>r});var i=s(14041);const t={},o=i.createContext(t);function a(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);