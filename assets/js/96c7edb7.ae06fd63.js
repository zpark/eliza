"use strict";(self.webpackChunk_elizaos_docs=self.webpackChunk_elizaos_docs||[]).push([[8662],{71184:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(14041);const r={},s=i.createContext(r);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(s.Provider,{value:n},e.children)}},78804:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"interfaces/DetokenizeTextParams","title":"DetokenizeTextParams","description":"@elizaos/core v1.0.12 / DetokenizeTextParams","source":"@site/api/interfaces/DetokenizeTextParams.md","sourceDirName":"interfaces","slug":"/interfaces/DetokenizeTextParams","permalink":"/api/interfaces/DetokenizeTextParams","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"DeriveKeyAttestationData","permalink":"/api/interfaces/DeriveKeyAttestationData"},"next":{"title":"DirectoryItem","permalink":"/api/interfaces/DirectoryItem"}}');var r=t(31085),s=t(71184);const o={},a="Interface: DetokenizeTextParams",c={},d=[{value:"Properties",id:"properties",level:2},{value:"tokens",id:"tokens",level:3},{value:"Defined in",id:"defined-in",level:4},{value:"modelType",id:"modeltype",level:3},{value:"Defined in",id:"defined-in-1",level:4}];function l(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"/api/",children:"@elizaos/core v1.0.12"})," / DetokenizeTextParams"]}),"\n",(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"interface-detokenizetextparams",children:"Interface: DetokenizeTextParams"})}),"\n",(0,r.jsxs)(n.p,{children:["Parameters for detokenizing text, i.e., converting a sequence of numerical tokens back into a string.\nThis is the reverse operation of tokenization.\nThis structure is used with ",(0,r.jsx)(n.code,{children:"AgentRuntime.useModel"})," when the ",(0,r.jsx)(n.code,{children:"modelType"})," is ",(0,r.jsx)(n.code,{children:"ModelType.TEXT_TOKENIZER_DECODE"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"properties",children:"Properties"}),"\n",(0,r.jsx)(n.h3,{id:"tokens",children:"tokens"}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tokens"}),": ",(0,r.jsx)(n.code,{children:"number"}),"[]"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"An array of numerical tokens to be converted back into text."}),"\n",(0,r.jsx)(n.h4,{id:"defined-in",children:"Defined in"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://github.com/zpark/eliza/blob/main/packages/core/src/types/model.ts#L70",children:"packages/core/src/types/model.ts:70"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"modeltype",children:"modelType"}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"modelType"}),": ",(0,r.jsx)(n.code,{children:"string"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The model type used for detokenization, ensuring consistency with the original tokenization."}),"\n",(0,r.jsx)(n.h4,{id:"defined-in-1",children:"Defined in"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://github.com/zpark/eliza/blob/main/packages/core/src/types/model.ts#L72",children:"packages/core/src/types/model.ts:72"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);